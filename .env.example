# Configuration pour version Cloud
# Copiez ce fichier en .env et ajoutez vos clés

# Port du serveur
PORT=3000

# Configuration API LLM (choisissez-en une)
# Option 1: OpenAI (recommandé)
OPENAI_API_KEY=sk-your-openai-api-key-here
LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini

# Option 2: Anthropic Claude
# ANTHROPIC_API_KEY=sk-ant-your-claude-key-here
# LLM_PROVIDER=anthropic
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# Option 3: Local Ollama (fallback)
# OLLAMA_ENABLED=true
# OLLAMA_MODEL=mistral
# OLLAMA_URL=http://localhost:11434

# Base de données (optionnel pour le cloud)
# DATABASE_URL=postgresql://user:password@localhost:5432/tsa_assistant
# Pour le développement, utilise le stockage local par défaut
