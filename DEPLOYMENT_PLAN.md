# Plan de d√©ploiement et progression des am√©liorations ‚Äî TSA Assistant

Date: 2025-11-30 (mis √† jour)

Objectif: fournir une progression claire, it√©rative et r√©versible pour am√©liorer la qualit√© des r√©ponses en partant d'une base locale (heuristique + feedback), puis en ajoutant retrieval (RAG l√©ger) et, si souhait√©, un LLM local.

Priorit√©s et phasage

## Phase 0 ‚Äî Stabilisation (d√©j√† r√©alis√©e)
- Application minimale locale sans d√©pendance √† Ollama.
- Endpoints: `/ask`, `/feedback` (sauvegarde locale), onboarding et profil.
- UI: chat simplifi√© et boutons de feedback (üëç/üëé) par r√©ponse.

## Phase 1 ‚Äî Option A : Exemples positifs & endpoints (r√©alis√©e)
But: extraire rapidement les exemples ¬´ qui marchent ¬ª √† partir des retours positifs pour am√©liorer les r√©ponses.

T√¢ches r√©alis√©es:
- Cr√©ation de `data/examples.json` (magasin d'exemples positifs).
- Endpoint `GET /examples` pour r√©cup√©rer les paires (message ‚Üí reply).
- Endpoint `POST /rebuild-index` pour reconstruire `examples.json` √† partir de `data/feedback.json` (d√©duplication par texte de r√©ponse).
- Les retours positifs (`helpful=true`) ajoutent automatiquement de nouveaux exemples (si non dupliqu√©s).

√âtat actuel suppl√©mentaire (par rapport au plan initial):
- `/ask` c√¥t√© Node a √©t√© enrichi avec une heuristique plus avanc√©e:
  - prise en compte du profil utilisateur (longueur pr√©f., format pr√©f., besoin de validation √©motionnelle),
  - d√©tection simple de cas d‚Äôusage (organisation, communication, rendez-vous, routine, surcharge √©motionnelle, autre),
  - r√©ponses sp√©cialis√©es par cas d‚Äôusage et modes (`standard`, `surcharge`, `planification`).

B√©n√©fices: permet d'avoir rapidement un corpus de bonnes r√©ponses utilisables pour retrieval ou few-shot, et un comportement utile m√™me sans LLM.

## Phase 2 ‚Äî Retrieval-augmented generation (RAG) l√©ger (en cours)
But: utiliser les exemples positifs pour fournir des r√©ponses plus pertinentes sans entra√Ænement.

### √âtat actuel
- Un micro-service d'embeddings local existe d√©j√†: `embeddings_service.py`.
  - Utilise `sentence-transformers` (mod√®le `all-MiniLM-L6-v2`).
  - Charge `data/examples.json` au d√©marrage.
  - Calcule et normalise les embeddings en m√©moire.
  - Expose les endpoints:
    - `GET /health` pour v√©rifier l‚Äô√©tat du service et le nombre d‚Äôexemples charg√©s.
    - `POST /reindex` pour recharger `examples.json` et recalculer les embeddings.
    - `POST /similar { "query": "...", "k": 5 }` pour retourner les top‚ÄëK exemples les plus proches avec leur score de similarit√©.

### T√¢ches restantes
- C√¢bler l‚Äôapplication Node √† ce micro-service:
  - Ajouter dans `/ask` un appel HTTP √† `POST http://127.0.0.1:8700/similar` avec le `message` de l‚Äôutilisateur.
  - Renvoyer dans la r√©ponse JSON les top‚ÄëK exemples trouv√©s (champ `examples`), sans forc√©ment les afficher tous c√¥t√© UI au d√©but.
  - Pr√©voir la gestion des erreurs (service down, pas d‚Äôexemples, etc.).
- Am√©liorer la qualit√© et la structure de `examples.json` pour un RAG plus pertinent:
  - Enrichir chaque exemple avec:
    - le cas d‚Äôusage d√©tect√© (`use_case`),
    - un snapshot minimal du profil (type de fonctionnement, longueur/format pr√©f√©r√©s, besoin de validation),
    - un score de qualit√© (bas√© sur le feedback positif/n√©gatif et la r√©cence).
  - Mettre en place des r√®gles simples de nettoyage:
    - ignorer les r√©ponses trop courtes ou trop g√©n√©riques,
    - d√©dupliquer/mettre √† jour les exemples tr√®s similaires,
    - optionnel: endpoint de maintenance pour purger les exemples de faible qualit√©.
- (Optionnel) Utiliser les exemples retourn√©s par le service d‚Äôembeddings pour enrichir la r√©ponse:
  - soit en les affichant dans l‚ÄôUI comme ¬´ r√©ponses similaires qui ont bien aid√© d‚Äôautres personnes ¬ª,
  - soit en les injectant comme contexte/few‚Äëshot dans le prompt envoy√© √† un LLM (lorsque activ√©).

## Phase 3 ‚Äî LLM local quantifi√© + LoRA (long terme, √† planifier)
But: disposer d'un mod√®le g√©n√©ratif local personnalis√© sur le style/contraintes TSA/TDAH, en s‚Äôappuyant sur le corpus d‚Äôexemples positifs.

T√¢ches propos√©es (inchang√©es, mais √† r√©aliser plus tard):
- Installer `llama.cpp` / `ctransformers` ou un runtime Windows compatible.
- T√©l√©charger un mod√®le 7B quantifi√© (ggml) compatible (ex: vicuna-7b-ggml-q4*), v√©rifier la licence.
- Optionnel: collecter un dataset d'exemples positifs (depuis `examples.json`) et faire un fine-tuning LoRA pour adapter le style et les comportements.
- D√©ployer le mod√®le local et remplacer (ou combiner) la logique heuristique par une g√©n√©ration RAG + LLM (en conservant les garde-fous √©thiques et de s√©curit√© d√©crits ci-dessous).

S√©curit√©, √©thique et licences
- Toujours v√©rifier la licence du mod√®le utilis√© (LLaMA/Llama2, Mistral, Falcon, etc.).
- Ne pas envoyer de donn√©es sensibles √† des services tiers sans consentement explicite.
- Conserver les donn√©es localement par d√©faut; pr√©voir des m√©canismes d'export et de purge.

Plan de livrables et d√©lai estim√© (r√©vis√©)
- J+0 (imm√©diat) :
  - Option A ‚Äî exemples export + endpoints (fait).
  - Am√©lioration heuristique de `/ask` align√©e avec le profil TSA/TDAH (fait).
- J+1‚Äì3 :
  - Lancer et stabiliser le micro-service d‚Äôembeddings `embeddings_service.py` (fait c√¥t√© code, √† automatiser c√¥t√© run si besoin).
  - C√¢bler `/ask` au service d‚Äôembeddings pour retourner les top‚ÄëK exemples (√† faire).
  - Commencer √† enrichir la structure de `examples.json` (use_case, profil, score) pour un RAG de meilleure qualit√© (√† faire).
- J+4‚Äì10 :
  - Exp√©rimenter l‚Äôint√©gration d‚Äôun petit LLM local quantifi√© (7B) pour la g√©n√©ration compl√®te, si le mat√©riel le permet.
  - Tester la combinaison heuristique + RAG + LLM en gardant les contraintes TSA/TDAH (structure des r√©ponses, validation √©motionnelle, modes surcharge/planification).

Commandes utiles (Windows PowerShell)
- Installer Python + virtualenv (recommand√© pour embeddings):
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install sentence-transformers faiss-cpu flask
```
- Rebuild des exemples via l'API (local):
```powershell
Invoke-RestMethod -Uri http://localhost:3000/rebuild-index -Method Post
```

Proposition imm√©diate suivante
- Poursuivre l‚Äôint√©gration RAG l√©ger:
  - C√¢bler `/ask` au micro-service d‚Äôembeddings pour retourner les top‚ÄëK exemples.
  - Commencer √† enrichir/structurer `examples.json` afin d‚Äôam√©liorer progressivement la pertinence des suggestions.

---

Fin du plan.
